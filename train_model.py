# train_model.py
import tensorflow as tf
import numpy as np
import os
from glob import glob


# ======================
# é…ç½®å‚æ•°
# ======================
class Config:
    BATCH_SIZE = 64
    EPOCHS = 50
    INPUT_SHAPE = (30, 31, 1)  # MFCCç‰¹å¾ç»´åº¦
    SAMPLE_RATE = 16000
    NUM_MFCC = 31
    NUM_FRAMES = 30


# ======================
# Metal GPUé…ç½®
# ======================
def configure_metal():
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        try:
            # é…ç½®å†…å­˜å¢é•¿å’Œæ˜¾å­˜é™åˆ¶
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
                tf.config.set_logical_device_configuration(
                    gpu,
                    [tf.config.LogicalDeviceConfiguration(memory_limit=4096)]
                )
            print(f"âœ… Metal GPUå·²é…ç½® | æ˜¾å­˜é™åˆ¶: 4096MB")
        except RuntimeError as e:
            print("âš ï¸ é…ç½®é”™è¯¯:", e)


# ======================
# æ•°æ®ç®¡é“ï¼ˆå…³é”®ä¿®æ­£ï¼‰
# ======================
def build_data_pipeline():
    def _parse_function(example_proto):
        # ä¿®æ­£ç‰¹å¾è§£ææè¿°
        feature_description = {
            'feature': tf.io.FixedLenFeature([Config.NUM_FRAMES * Config.NUM_MFCC], tf.float32),
            'label': tf.io.FixedLenFeature([], tf.int64)
        }
        parsed = tf.io.parse_single_example(example_proto, feature_description)
        return parsed['feature'], parsed['label']

    def _preprocess(feature, label):
        # å…ˆreshapeå†ç±»å‹è½¬æ¢
        feature = tf.reshape(feature, (Config.NUM_FRAMES, Config.NUM_MFCC, 1))
        return tf.cast(feature, tf.float32), tf.cast(label, tf.int32)

    # æ„å»ºè®­ç»ƒç®¡é“
    train_ds = tf.data.TFRecordDataset(glob("dataset/train/*.tfrecord"))
    train_ds = (
        train_ds
        .map(_parse_function, num_parallel_calls=tf.data.AUTOTUNE)
        .map(_preprocess, num_parallel_calls=tf.data.AUTOTUNE)
        .shuffle(1000)
        .batch(Config.BATCH_SIZE)
        .prefetch(tf.data.AUTOTUNE)
    )

    # æ„å»ºéªŒè¯ç®¡é“
    val_ds = tf.data.TFRecordDataset(glob("dataset/val/*.tfrecord"))
    val_ds = (
        val_ds
        .map(_parse_function, num_parallel_calls=tf.data.AUTOTUNE)
        .map(_preprocess, num_parallel_calls=tf.data.AUTOTUNE)
        .batch(Config.BATCH_SIZE)
        .prefetch(tf.data.AUTOTUNE)
    )

    return train_ds, val_ds


# ======================
# æ¨¡å‹æ¶æ„ï¼ˆé€‚é…è¾“å…¥ç»´åº¦ï¼‰
# ======================
def build_model():
    model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=Config.INPUT_SHAPE),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.MaxPool2D(2),

        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.MaxPool2D(2),

        tf.keras.layers.GlobalAveragePooling2D(),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dropout(0.3),
        tf.keras.layers.Dense(1, activation='sigmoid')
    ])

    model.compile(
        optimizer=tf.keras.optimizers.Adam(3e-4),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    return model


# ======================
# æ•°æ®éªŒè¯ï¼ˆæ–°å¢ï¼‰
# ======================
def validate_data():
    # éªŒè¯å•ä¸ªæ ·æœ¬
    sample_path = glob("dataset/train/*.tfrecord")[0]
    sample_ds = tf.data.TFRecordDataset(sample_path).take(1)

    for raw_record in sample_ds:
        example = tf.train.Example()
        example.ParseFromString(raw_record.numpy())
        feature = np.array(example.features.feature['feature'].float_list.value)
        assert len(feature) == Config.NUM_FRAMES * Config.NUM_MFCC, \
            f"âŒ ç‰¹å¾ç»´åº¦é”™è¯¯: é¢„æœŸ{Config.NUM_FRAMES * Config.NUM_MFCC} å®é™…{len(feature)}"

    # éªŒè¯é¢„å¤„ç†ç®¡é“
    train_ds, _ = build_data_pipeline()
    sample_batch = next(iter(train_ds))
    features, labels = sample_batch
    assert features.shape[1:] == Config.INPUT_SHAPE, \
        f"âŒ è¾“å…¥å½¢çŠ¶é”™è¯¯: é¢„æœŸ{Config.INPUT_SHAPE} å®é™…{features.shape[1:]}"
    print("âœ… æ•°æ®éªŒè¯é€šè¿‡")


# ======================
# è®­ç»ƒæµç¨‹
# ======================
def main():
    configure_metal()
    validate_data()

    train_ds, val_ds = build_data_pipeline()
    model = build_model()

    # è®­ç»ƒå›è°ƒ
    callbacks = [
        tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),
        tf.keras.callbacks.ModelCheckpoint("best_model.keras", save_best_only=True)
    ]

    # å¼€å§‹è®­ç»ƒ
    history = model.fit(
        train_ds,
        validation_data=val_ds,
        epochs=Config.EPOCHS,
        callbacks=callbacks
    )

    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    model.save("/models/xiaozhi_detector.keras")
    print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")


if __name__ == "__main__":
    main()
